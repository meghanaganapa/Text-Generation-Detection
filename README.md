
Text Generation Detection: A Kaggle Competition Project
Overview
Text generation, powered by advances in natural language processing (NLP) and deep learning, has become a critical tool for various applications such as chatbots, language translation, and content creation. These models generate text by predicting likely sequences based on extensive training datasets from news articles, books, and web-scraped data. Despite its advantages, text generation poses challenges in ensuring the authenticity, accuracy, and authoritativeness of the content. This project addresses these challenges by developing models to detect whether a given text is machine-generated or human-written.

Objective
The primary objective of this project is to predict whether given text input instances are generated by a human or a machine. The project is conducted as part of a Kaggle competition, with participants required to submit test predictions based on provided training and test data.

Data Description

Training Data:
Dataset1 (Domain1): Contains both human-generated and machine-generated text.
Dataset2 (Domain2): Contains both human-generated and machine-generated text, with an imbalance favoring machine-generated samples.

Test Data:
Balanced distribution of human-generated and machine-generated text from both Domain1 and Domain2.
The datasets are preprocessed into tokens and mapped to indices ranging from 0 to 83582, with a special token 0 for unknown tokens. This numerical representation allows the focus to be on machine learning aspects.

Key Considerations:
Domain Generalization: The training data comes from two distinct domains, and the domain of test samples is not disclosed. Relevant techniques include domain generalization, domain adaptation, multitask learning, and ensemble learning.

Imbalanced Classification: 
The training data from Domain2 has fewer human-generated samples, while the test set is balanced. Techniques to address this include imbalanced classification methods, over/under sampling, and data augmentation.


